{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: scikit-learn survey\n",
    "subtitle: Presentation of survey results\n",
    "author:\n",
    "  - name: Inessa Pawson\n",
    "    email: ipawson@openteams.com\n",
    "date: 2024/12/27\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Data\n",
    "```{tip} Show code\n",
    ":class: dropdown \n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/Auslum/scikit_learn_survey/refs/heads/main/scikit-learn-survey-master-dataset.csv'\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "#print(df.head())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Future Direction and Priorities\n",
    "\n",
    "In the survey, new features, performance, and technical documentation have the highest priority for the users. While website redesign and other have the lowest.\n",
    "\n",
    "```{tip} Show code\n",
    ":class: dropdown \n",
    "\n",
    "```python\n",
    "# Define priority levels from 1 to 7\n",
    "priority_levels = list(range(1, 8))\n",
    "\n",
    "# Filter columns related to the question\n",
    "priority_columns = [col for col in df.columns if \"PROJECT FUTURE DIRECTION AND PRIORITIES\" in col]\n",
    "priority_data = df[priority_columns].dropna()\n",
    "\n",
    "# Rename the categories\n",
    "renamed_columns = [\n",
    "    \"Performance\", \"Reliability\", \"Packaging\", \"New features\",\n",
    "    \"Technical documentation\", \"Educational materials\",\n",
    "    \"Website redesign\", \"Other\"\n",
    "]\n",
    "priority_data.columns = renamed_columns\n",
    "\n",
    "# Convert the data to a long format for Altair\n",
    "priority_data_melted = priority_data.melt(var_name=\"Category\", value_name=\"Priority\")\n",
    "\n",
    "# Create interpolated colors from blue to orange\n",
    "scikit_learn_colors = [\"#0072B2\", \"#FF9900\"]\n",
    "priority_colors = [\n",
    "    mcolors.to_hex(c)\n",
    "    for c in mcolors.LinearSegmentedColormap.from_list(\"ScikitLearn\", scikit_learn_colors)(\n",
    "        np.linspace(0, 1, len(priority_levels))\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create custom labels for the legend\n",
    "priority_labels = {1: \"1 (Lowest priority)\", 2: \"2\", 3: \"3\", 4: \"4\", 5: \"5\", 6: \"6\", 7: \"7 (Highest priority)\"}\n",
    "priority_data_melted['Priority Label'] = priority_data_melted['Priority'].map(priority_labels)\n",
    "\n",
    "# Create the stacked bar chart with Altair\n",
    "chart = alt.Chart(priority_data_melted).mark_bar().encode(\n",
    "    x=alt.X('Category:N', title='Categories', sort=renamed_columns),\n",
    "    y=alt.Y(\n",
    "        'count()',\n",
    "        title='Frequency',\n",
    "        scale=alt.Scale(domain=[0, 350])\n",
    "    ),\n",
    "    color=alt.Color(\n",
    "        'Priority Label:N',\n",
    "        scale=alt.Scale(\n",
    "            domain=list(priority_labels.values()),\n",
    "            range=priority_colors\n",
    "        ),\n",
    "        title='Priority Level'\n",
    "    ),\n",
    "    order=alt.Order('Priority:Q', sort='ascending')\n",
    ").properties(\n",
    "    title=\"Project Future Direction And Priorities\",\n",
    "    width=600,\n",
    "    height=400\n",
    ").configure_axis(\n",
    "    labelAngle=45\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "chart.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Project Future Direction and Priorities](images/chart1.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Tasks: Priority Levels\n",
    "\n",
    "Talking about Machine Learning tasks, classification and regression have the highest priorities, while other, outlier/anomaly detection, and clustering have the lowest ones.\n",
    "\n",
    "```{tip} Show code\n",
    ":class: dropdown \n",
    "\n",
    "```python\n",
    "\n",
    "# Define priority levels from 1 to 7\n",
    "priority_levels = list(range(1, 8))\n",
    "\n",
    "# Filter columns related to the question\n",
    "priority_columns = [col for col in df.columns if \"Please order the following ML tasks in order of priority to you\" in col]\n",
    "priority_data = df[priority_columns].dropna()\n",
    "\n",
    "# Rename the categories\n",
    "renamed_columns = [\n",
    "    \"Regression\", \"Classification\", \"Forecasting\",\n",
    "    \"Outlier/anomaly detection\", \"Dimensionality reduction\",\n",
    "    \"Clustering\", \"Other\"\n",
    "]\n",
    "priority_data.columns = renamed_columns\n",
    "\n",
    "# Convert the data to a long format for Altair\n",
    "priority_data_melted = priority_data.melt(var_name=\"Category\", value_name=\"Priority\")\n",
    "\n",
    "# Create interpolated colors from blue to orange\n",
    "scikit_learn_colors = [\"#0072B2\", \"#FF9900\"]\n",
    "priority_colors = [\n",
    "    mcolors.to_hex(c)\n",
    "    for c in mcolors.LinearSegmentedColormap.from_list(\"ScikitLearn\", scikit_learn_colors)(\n",
    "        np.linspace(0, 1, len(priority_levels))\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create custom labels for the legend\n",
    "priority_labels = {1: \"1 (Lowest priority)\", 2: \"2\", 3: \"3\", 4: \"4\", 5: \"5\", 6: \"6\", 7: \"7 (Highest priority)\"}\n",
    "priority_data_melted['Priority Label'] = priority_data_melted['Priority'].map(priority_labels)\n",
    "\n",
    "# Create the stacked bar chart with Altair\n",
    "chart = alt.Chart(priority_data_melted).mark_bar().encode(\n",
    "    x=alt.X('Category:N', title='Categories', sort=renamed_columns),\n",
    "    y=alt.Y(\n",
    "        'count()',\n",
    "        title='Frequency',\n",
    "        scale=alt.Scale(domain=[0, 350])\n",
    "    ),\n",
    "    color=alt.Color(\n",
    "        'Priority Label:N',\n",
    "        scale=alt.Scale(\n",
    "            domain=list(priority_labels.values()),\n",
    "            range=priority_colors\n",
    "        ),\n",
    "        title='Priority Level'\n",
    "    ),\n",
    "    order=alt.Order('Priority:Q', sort='ascending')\n",
    ").properties(\n",
    "    title=\"ML Tasks: Priority Levels\",\n",
    "    width=600,\n",
    "    height=400\n",
    ").configure_axis(\n",
    "    labelAngle=45\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ML Tasks: Priority Levels](images/chart2.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations used to evaluate models\n",
    "\n",
    "The majority of respondents use confusion matrix the most as visualization to evaluate models, feature importance and ROC curve are commonly used as well. Residual plots and reliability diagrams are the least used.\n",
    "\n",
    "```{tip} Show code\n",
    ":class: dropdown \n",
    "\n",
    "```python\n",
    "\n",
    "# Mapping dictionary\n",
    "mapping_dict = {\n",
    "    # Confusion matrix responses\n",
    "    \"Confusion matrix\": \"Confusion matrix\",\n",
    "    \"Matriz de confusão\": \"Confusion matrix\",\n",
    "    \"Matriz de confusión\": \"Confusion matrix\",\n",
    "    \"混淆矩阵\": \"Confusion matrix\",\n",
    "    \"Matrice de confusion\": \"Confusion matrix\",\n",
    "    \"مصفوفة الدقة\": \"Confusion matrix\",\n",
    "    # Reliability diagram responses\n",
    "    \"Reliability diagram\": \"Reliability diagram\",\n",
    "    \"Diagrama de confiabilidade\": \"Reliability diagram\",\n",
    "    \"Diagrama de confiabilidad\": \"Reliability diagram\",\n",
    "    \"可靠性图\": \"Reliability diagram\",\n",
    "    \"Diagramme de fiabilité\": \"Reliability diagram\",\n",
    "    \"مخطط الموثوقية\": \"Reliability diagram\",\n",
    "    # ROC curve responses\n",
    "    \"ROC curve\": \"ROC curve\",\n",
    "    \"Curva ROC\": \"ROC curve\",\n",
    "    \"ROC曲线\": \"ROC curve\",\n",
    "    \"Courbe ROC\": \"ROC curve\",\n",
    "    \"منحنى ROC\": \"ROC curve\",\n",
    "    # Precision-Recall curve responses\n",
    "    \"Precision-Recall curve\": \"Precision-Recall curve\",\n",
    "    \"Curva de Precisão-Recall\": \"Precision-Recall curve\",\n",
    "    \"Curva de Precisión-Recall\": \"Precision-Recall curve\",\n",
    "    \"PR曲线（精确率-召回率曲线）\": \"Precision-Recall curve\",\n",
    "    \"Courbe Précision-Rappel\": \"Precision-Recall curve\",\n",
    "    \"منحنى الدقة-الاسترجاع\": \"Precision-Recall curve\",\n",
    "    # Feature importance responses\n",
    "    \"Feature importance\": \"Feature importance\",\n",
    "    \"Importância das características\": \"Feature importance\",\n",
    "    \"Importancia de variables\": \"Feature importance\",\n",
    "    \"特征重要性\": \"Feature importance\",\n",
    "    \"Importance des caractéristiques (features)\": \"Feature importance\",\n",
    "    \"الأهمية النسبية للخواص\": \"Feature importance\",\n",
    "    # Residual plots responses\n",
    "    \"Residual plots\": \"Residual plots\",\n",
    "    \"Gráficos de resíduos\": \"Residual plots\",\n",
    "    \"Gráficos de residuos\": \"Residual plots\",\n",
    "    \"残差图\": \"Residual plots\",\n",
    "    \"Graphiques des résidus\": \"Residual plots\",\n",
    "    \"مخططات البواقي\": \"Residual plots\",\n",
    "    # Learning curves responses\n",
    "    \"Learning curves\": \"Learning curves\",\n",
    "    \"Curvas de aprendizagem\": \"Learning curves\",\n",
    "    \"Curvas de aprendizaje\": \"Learning curves\",\n",
    "    \"学习曲线\": \"Learning curves\",\n",
    "    \"Courbes d'apprentissage\": \"Learning curves\",\n",
    "    \"منحنيات التعلم\": \"Learning curves\",\n",
    "    # Other responses\n",
    "    \"Other\": \"Other\",\n",
    "    \"Outro\": \"Other\",\n",
    "    \"Otro\": \"Other\",\n",
    "    \"其它\": \"Other\",\n",
    "    \"Autre\": \"Other\",\n",
    "    \"أخرى\": \"Other\"\n",
    "}\n",
    "\n",
    "# Function to normalize responses\n",
    "def normalize_responses(response):\n",
    "    if isinstance(response, str):\n",
    "        response_split = [r.strip() for r in response.split(',')]\n",
    "        normalized = [mapping_dict.get(r, None) for r in response_split]\n",
    "        return [r for r in normalized if r is not None]\n",
    "    return []\n",
    "\n",
    "# Apply normalization and count responses\n",
    "df['Normalized_Responses'] = df['What visualizations do you use to evaluate your models? Select all that apply.'].apply(normalize_responses)\n",
    "all_responses = [item for sublist in df['Normalized_Responses'].dropna() for item in sublist]\n",
    "response_counts = pd.Series(all_responses).value_counts().reset_index()\n",
    "response_counts.columns = ['Visualization', 'Count']\n",
    "\n",
    "# Chart using Altair with orange color\n",
    "chart = alt.Chart(response_counts).mark_bar(color='#F7931E').encode(\n",
    "    x='Count:Q',\n",
    "    y=alt.Y('Visualization:N', sort='-x'),\n",
    "    tooltip=['Visualization', 'Count']\n",
    ").properties(\n",
    "    title='Visualizations used to evaluate models',\n",
    "    width=500,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Visualizations used to evaluate models](images/chart3.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe libraries used\n",
    "\n",
    "Pandas is the most used library for the majority of respondents. Other libraries are not so popular compared to pandas, being Modin the least used.\n",
    "\n",
    "```{tip} Show code\n",
    ":class: dropdown \n",
    "\n",
    "```python\n",
    "\n",
    "# Mapping dictionary\n",
    "mapping_dict = {\n",
    "    # cudf responses\n",
    "    \"cudf\": \"cudf\",\n",
    "    \"cuDF كووديف\": \"cudf\",\n",
    "    # Dask DataFrame responses\n",
    "    \"Dask DataFrame\": \"Dask DataFrame\",\n",
    "    \"Dask 数据框\": \"Dask DataFrame\",\n",
    "    \"Dask DataFrame  اطر بيانات داسك\": \"Dask DataFrame\",\n",
    "    # DuckDB responses\n",
    "    \"DuckDB\": \"DuckDB\",\n",
    "    \"DuckDB دك دي بي\": \"DuckDB\",\n",
    "    # Modin responses\n",
    "    \"Modin\": \"Modin\",\n",
    "    \"Modin مودين\": \"Modin\",\n",
    "    # pandas responses\n",
    "    \"pandas\": \"pandas\",\n",
    "    \"Pandas\": \"pandas\",\n",
    "    \"pandas بنداز\": \"pandas\",\n",
    "    # Polars responses\n",
    "    \"Polars\": \"Polars\",\n",
    "    \"Polars بولارز\": \"Polars\",\n",
    "    # Spark DataFrame responses\n",
    "    \"Spark DataFrame\": \"Spark DataFrame\",\n",
    "    \"Spark 数据框\": \"Spark DataFrame\",\n",
    "    \"Spark DataFrame اطر بيانات سبارك\": \"Spark DataFrame\",\n",
    "    # Other responses\n",
    "    \"Other\": \"Other\",\n",
    "    \"Outro\": \"Other\",\n",
    "    \"Otro\": \"Other\",\n",
    "    \"其它\": \"Other\",\n",
    "    \"Autre\": \"Other\",\n",
    "    \"أخرى\": \"Other\"\n",
    "}\n",
    "\n",
    "# Function to normalize responses\n",
    "def normalize_responses(response):\n",
    "    if isinstance(response, str):\n",
    "        response_split = [r.strip() for r in response.split(',')]\n",
    "        normalized = [mapping_dict.get(r, None) for r in response_split]\n",
    "        return [r for r in normalized if r is not None]\n",
    "    return []\n",
    "\n",
    "# Apply normalization and count responses\n",
    "df['Normalized_Responses'] = df['Which DataFrame libraries do you use? Select all that apply.'].apply(normalize_responses)\n",
    "all_responses = [item for sublist in df['Normalized_Responses'].dropna() for item in sublist]\n",
    "response_counts = pd.Series(all_responses).value_counts().reset_index()\n",
    "response_counts.columns = ['Libraries', 'Count']\n",
    "\n",
    "# Chart using Altair with orange color\n",
    "chart = alt.Chart(response_counts).mark_bar(color='#F7931E').encode(\n",
    "    x='Count:Q',\n",
    "    y=alt.Y('Libraries:N', sort='-x'),\n",
    "    tooltip=['Libraries', 'Count']\n",
    ").properties(\n",
    "    title='DataFrame libraries used',\n",
    "    width=500,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Dataframe libraries used](images/chart4.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning libraries used\n",
    "\n",
    "For Machine Learning, XGBoost and PyTorch are the most used libraries, while Jax is the least used.\n",
    "\n",
    "```{tip} Show code\n",
    ":class: dropdown \n",
    "\n",
    "```python\n",
    "\n",
    "# Mapping dictionary\n",
    "mapping_dict = {\n",
    "    # CatBoost responses\n",
    "    \"CatBoost\": \"CatBoost\",\n",
    "    \"CatBoost كات بوست\": \"CatBoost\",\n",
    "    # Jax responses\n",
    "    \"Jax\": \"Jax\",\n",
    "    \"JAX چاكس\": \"Jax\",\n",
    "    # Keras responses\n",
    "    \"Keras\": \"Keras\",\n",
    "    \"Keras كيراس\": \"Keras\",\n",
    "    # LightGBM responses\n",
    "    \"LightGBM\": \"LightGBM\",\n",
    "    \"LightGBM لايت جي بي ام\": \"LightGBM\",\n",
    "    # PyTorch responses\n",
    "    \"PyTorch\": \"PyTorch\",\n",
    "    \"PyTorch باي تورش\": \"PyTorch\",\n",
    "    # Transformers responses\n",
    "    \"Transformers\": \"Transformers\",\n",
    "    \"Transformers المحولات (ترانسفورمرز)\": \"Transformers\",\n",
    "    # XGBoost responses\n",
    "    \"XGBoost\": \"XGBoost\",\n",
    "    \"XGBoost اكس جي بوست\": \"XGBoost\",\n",
    "    # Other responses\n",
    "    \"Other\": \"Other\",\n",
    "    \"Outro\": \"Other\",\n",
    "    \"Otro\": \"Other\",\n",
    "    \"其它\": \"Other\",\n",
    "    \"Autre\": \"Other\",\n",
    "    \"أخرى\": \"Other\"\n",
    "}\n",
    "\n",
    "# Function to normalize responses\n",
    "def normalize_responses(response):\n",
    "    if isinstance(response, str):\n",
    "        response_split = [r.strip() for r in response.split(',')]\n",
    "        normalized = [mapping_dict.get(r, None) for r in response_split]\n",
    "        return [r for r in normalized if r is not None]\n",
    "    return []\n",
    "\n",
    "# Apply normalization and count responses\n",
    "df['Normalized_Responses'] = df['Which other Machine Learning libraries do you use? Select all that apply.'].apply(normalize_responses)\n",
    "all_responses = [item for sublist in df['Normalized_Responses'].dropna() for item in sublist]\n",
    "response_counts = pd.Series(all_responses).value_counts().reset_index()\n",
    "response_counts.columns = ['Libraries', 'Count']\n",
    "\n",
    "# Chart using Altair with orange color\n",
    "chart = alt.Chart(response_counts).mark_bar(color='#F7931E').encode(\n",
    "    x='Count:Q',\n",
    "    y=alt.Y('Libraries:N', sort='-x'),\n",
    "    tooltip=['Libraries', 'Count']\n",
    ").properties(\n",
    "    title='Machine Learning libraries used',\n",
    "    width=500,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine Learning libraries used](images/chart5.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators regularly used\n",
    "\n",
    "RandomForestClassifier and RandomForestRegressor are the most used estimators, other estimators that are not listed in the options given in the survey, HistGradientBoostingRegresor and HistGradientBoostingClassifier are the least used.\n",
    "\n",
    "```{tip} Show code\n",
    ":class: dropdown \n",
    "\n",
    "```python\n",
    "# Mapping dictionary\n",
    "mapping_dict = {\n",
    "     # LogisticRegression responses\n",
    "    \"LogisticRegression\": \"LogisticRegression\",\n",
    "    \"RandomForestClassifier أو RandomForestRegressorLogisticRegression الانحدار اللوجستي\": \"LogisticRegression\",\n",
    "    # RandomForestClassifier or RandomForestRegressor responses\n",
    "    \"RandomForestClassifier or RandomForestRegressor\": \"RandomForestClassifier or RandomForestRegressor\",\n",
    "    \"RandomForestClassifier ou RandomForestRegressor\": \"RandomForestClassifier or RandomForestRegressor\",\n",
    "    \"RandomForestClassifier o RandomForestRegressor\": \"RandomForestClassifier or RandomForestRegressor\",\n",
    "    \"RandomForestClassifier 或 RandomForestRegressor\": \"RandomForestClassifier or RandomForestRegressor\",\n",
    "    \"مصنف الغابة العشوائية أو انحدار الغابة العشوائية\": \"RandomForestClassifier or RandomForestRegressor\",\n",
    "    # HistGradientBoostingRegressor or HistGradientBoostingClassifier responses\n",
    "    \"HistGradientBoostingRegressor or HistGradientBoostingClassifier\": \"HistGradientBoostingRegressor or HistGradientBoostingClassifier\",\n",
    "    \"HistGradientBoostingRegressor ou HistGradientBoostingClassifier\": \"HistGradientBoostingRegressor or HistGradientBoostingClassifier\",\n",
    "    \"HistGradientBoostingRegressor o HistGradientBoostingClassifier\": \"HistGradientBoostingRegressor or HistGradientBoostingClassifier\",\n",
    "    \"HistGradientBoostingRegressor 或 HistGradientBoostingClassifier\": \"HistGradientBoostingRegressor or HistGradientBoostingClassifier\",\n",
    "    \"HistGradientBoostingRegressorأو HistGradientBoostingClassifier  مصنف الانحدار المدعم بتحليل التردد أو شجرة الانحدار المدعمة بتحليل التردد</li>\": \"HistGradientBoostingRegressor or HistGradientBoostingClassifier\",\n",
    "    # Pipeline responses\n",
    "    \"Pipeline\": \"Pipeline\",\n",
    "    \"Pipeline الوصلات \\ خطوط الأنابيب\": \"Pipeline\",\n",
    "    # ColumnTransformer responses\n",
    "    \"ColumnTransformer\": \"ColumnTransformer\",\n",
    "    \"ColumnTransforme محولات الاعمدة\": \"ColumnTransformer\",\n",
    "    # Other responses\n",
    "    \"Other\": \"Other\",\n",
    "    \"Outro\": \"Other\",\n",
    "    \"Otro\": \"Other\",\n",
    "    \"其它\": \"Other\",\n",
    "    \"Autre\": \"Other\",\n",
    "    \"أخرى\": \"Other\"\n",
    "}\n",
    "\n",
    "# Function to normalize responses\n",
    "def normalize_responses(response):\n",
    "    if isinstance(response, str):\n",
    "        response_split = [r.strip() for r in response.split(',')]\n",
    "        normalized = [mapping_dict.get(r, None) for r in response_split]\n",
    "        return [r for r in normalized if r is not None]\n",
    "    return []\n",
    "\n",
    "# Apply normalization and count responses\n",
    "df['Normalized_Responses'] = df['Which estimators do you regularly use? Select all that apply.'].apply(normalize_responses)\n",
    "all_responses = [item for sublist in df['Normalized_Responses'].dropna() for item in sublist]\n",
    "response_counts = pd.Series(all_responses).value_counts().reset_index()\n",
    "response_counts.columns = ['Estimators', 'Count']\n",
    "\n",
    "# Chart using Altair with orange color\n",
    "chart = alt.Chart(response_counts).mark_bar(color='#F7931E').encode(\n",
    "    x='Count:Q',\n",
    "    y=alt.Y('Estimators:N', sort='-x'),\n",
    "    tooltip=['Estimators', 'Count']\n",
    ").properties(\n",
    "    title='Estimators Regularly Used',\n",
    "    width=500,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Estimators regularly used](images/chart6.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important ML features\n",
    "\n",
    "The respondents consider that the most important Machine Learning features for use case are feature importances, and uncertainity estimates for prediction, and they consider that the least important are metadata routing and non-euclidean metrics.\n",
    "\n",
    "```{tip} Show code\n",
    ":class: dropdown \n",
    "\n",
    "```python\n",
    "# Mapping dictionary\n",
    "mapping_dict = {\n",
    "     # Calibration of probabilistic classifiers responses\n",
    "    \"Calibration of probabilistic classifiers\": \"Calibration of probabilistic classifiers\",\n",
    "    \"Calibração de classificadores probabilísticos\": \"Calibration of probabilistic classifiers\",\n",
    "    \"Calibración de clasificadores probabilísticos\": \"Calibration of probabilistic classifiers\",\n",
    "    \"概率分类器（probabilistic classifiers）的校准\": \"Calibration of probabilistic classifiers\",\n",
    "    \"Calibration des classificateurs probabilistes\": \"Calibration of probabilistic classifiers\",\n",
    "    \"معايرة المصنفات الاحتمالية\": \"Calibration of probabilistic classifiers\",\n",
    "    # Calibration of regressors responses\n",
    "    \"Calibration of regressors\": \"Calibration of regressors\",\n",
    "    \"Calibração de regressores\": \"Calibration of regressors\",\n",
    "    \"Calibración de regresores\": \"Calibration of regressors\",\n",
    "    \"回归子（regressor）的校准\": \"Calibration of regressors\",\n",
    "    \"Calibration des régressions\": \"Calibration of regressors\",\n",
    "    \"معايرة نماذج الانحدار\": \"Calibration of regressors\",\n",
    "    # Uncertainty estimates for prediction responses\n",
    "    \"Uncertainty estimates for prediction\": \"Uncertainty estimates for prediction\",\n",
    "    \"Estimativas de incerteza para previsão\": \"Uncertainty estimates for prediction\",\n",
    "    \"Estimaciones de incertidumbre para la predicción\": \"Uncertainty estimates for prediction\",\n",
    "    \"对预测的不确定性估计\": \"Uncertainty estimates for prediction\",\n",
    "    \"Estimations d'incertitude pour les prédictions\": \"Uncertainty estimates for prediction\",\n",
    "    \"تقديرات عدم اليقين للتنبؤ\": \"Uncertainty estimates for prediction\",\n",
    "    # Cost-sensitive learning responses\n",
    "    \"Cost-sensitive learning\": \"Cost-sensitive learning\",\n",
    "    \"Aprendizado sensível a custo\": \"Cost-sensitive learning\",\n",
    "    \"Aprendizaje sensible al costo (cost-sensitive learning)\": \"Cost-sensitive learning\",\n",
    "    \"代价敏感学习\": \"Cost-sensitive learning\",\n",
    "    \"Apprentissage sensible aux coûts (Cost-sensitive learning)\": \"Cost-sensitive learning\",\n",
    "    \"التعلم الحساس للتكلفة\": \"Cost-sensitive learning\",\n",
    "    # Feature importances responses\n",
    "    \"Feature importances\": \"Feature importances\",\n",
    "    \"Importância das características\": \"Feature importances\",\n",
    "    \"Importancia de variables\": \"Feature importances\",\n",
    "    \"特征重要性\": \"Feature importances\",\n",
    "    \"Importance des caractéristiques (features)\": \"Feature importances\",\n",
    "    \"الأهمية النسبية للخواص\": \"Feature importances\",\n",
    "    # Sample weights responses\n",
    "    \"Sample weights\": \"Sample weights\",\n",
    "    \"Pesos de amostra\": \"Sample weights\",\n",
    "    \"Pesos de muestra (sample weights)\": \"Sample weights\",\n",
    "    \"样本权重\": \"Sample weights\",\n",
    "    \"Poids des échantillons(Sample Weights)\": \"Sample weights\",\n",
    "    \"أوزان العينات\": \"Sample weights\",\n",
    "    # Metadata routing responses\n",
    "    \"Metadata routing\": \"Metadata routing\",\n",
    "    \"Roteamento de metadados\": \"Metadata routing\",\n",
    "    \"Enrutamiento de metadatos\": \"Metadata routing\",\n",
    "    \"元数据路由（Metadata routing）\": \"Metadata routing\",\n",
    "    \"Routage des métadonnées\": \"Metadata routing\",\n",
    "    \"توجيه البيانات الوصفية\": \"Metadata routing\",\n",
    "    # Non-euclidean metrics responses\n",
    "    \"Non-euclidean metrics\": \"Non-euclidean metrics\",\n",
    "    \"Métricas não-euclidianas\": \"Non-euclidean metrics\",\n",
    "    \"Métricas no-euclidianas\": \"Non-euclidean metrics\",\n",
    "    \"非欧几里得度量（Non-Euclidean Metric)\": \"Non-euclidean metrics\",\n",
    "    \"Métriques non-euclidiennes\": \"Non-euclidean metrics\",\n",
    "    \"المقاييس غير الإقليدية\": \"Non-euclidean metrics\",\n",
    "}\n",
    "\n",
    "# Function to normalize responses\n",
    "def normalize_responses(response):\n",
    "    if isinstance(response, str):\n",
    "        response_split = [r.strip() for r in response.split(',')]\n",
    "        normalized = [mapping_dict.get(r, None) for r in response_split]\n",
    "        return [r for r in normalized if r is not None]\n",
    "    return []\n",
    "\n",
    "# Apply normalization and count responses\n",
    "df['Normalized_Responses'] = df['What ML features are important for your use case? Select all that apply.'].apply(normalize_responses)\n",
    "all_responses = [item for sublist in df['Normalized_Responses'].dropna() for item in sublist]\n",
    "response_counts = pd.Series(all_responses).value_counts().reset_index()\n",
    "response_counts.columns = ['Features', 'Count']\n",
    "\n",
    "# Chart using Altair with orange color\n",
    "chart = alt.Chart(response_counts).mark_bar(color='#F7931E').encode(\n",
    "    x='Count:Q',\n",
    "    y=alt.Y('Features:N', sort='-x'),\n",
    "    tooltip=['Features', 'Count']\n",
    ").properties(\n",
    "    title='Important ML features',\n",
    "    width=500,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Important ML features](images/chart7.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools used for model registry and experiment tracking\n",
    "\n",
    "The most popular tool is MLFlow. Respondants do not use other tools as much as MLFlow, being Neptune the least popular among them.\n",
    "\n",
    "```{tip} Show code\n",
    ":class: dropdown \n",
    "\n",
    "```python\n",
    "# Mapping dictionary\n",
    "mapping_dict = {\n",
    "    # DVC responses\n",
    "    \"DVC\": \"DVC\",\n",
    "    \"DVC دي في سي\": \"DVC\",\n",
    "    # Neptune responses\n",
    "    \"Neptune\": \"Neptune\",\n",
    "    \"Neptune نبتون\": \"Neptune\",\n",
    "    # MLFlow responses\n",
    "    \"MLFlow\": \"MLFlow\",\n",
    "    \"MLFlow ام ال فلو\": \"MLFlow\",\n",
    "    # Weight and biases responses\n",
    "    \"Weight and biases\": \"Weight and biases\",\n",
    "    \"Weights and Biases\": \"Weight and biases\",\n",
    "    \"Weight and biases الوزن و الانحيازات\": \"Weight and biases\",\n",
    "    # Custom tool responses\n",
    "    \"Custom tool\": \"Custom tool\",\n",
    "    \"Ferramenta personalizada\": \"Custom tool\",\n",
    "    \"Herramientas personalizadas\": \"Custom tool\",\n",
    "    \"自定义工具\": \"Custom tool\",\n",
    "    \"Outil personnalisé\": \"Custom tool\",\n",
    "    \"أداة مخصصة\": \"Custom tool\",\n",
    "    # Other responses\n",
    "    \"Other\": \"Other\",\n",
    "    \"Outro\": \"Other\",\n",
    "    \"Otro\": \"Other\",\n",
    "    \"其它\": \"Other\",\n",
    "    \"Autre\": \"Other\",\n",
    "    \"أخرى\": \"Other\"\n",
    "}\n",
    "\n",
    "# Function to normalize responses\n",
    "def normalize_responses(response):\n",
    "    if isinstance(response, str):\n",
    "        response_split = [r.strip() for r in response.split(',')]\n",
    "        normalized = [mapping_dict.get(r, None) for r in response_split]\n",
    "        return [r for r in normalized if r is not None]\n",
    "    return []\n",
    "\n",
    "# Apply normalization and count responses\n",
    "df['Normalized_Responses'] = df['For model registry and experiment tracking, do you use any of the following tools? Select all that apply.'].apply(normalize_responses)\n",
    "all_responses = [item for sublist in df['Normalized_Responses'].dropna() for item in sublist]\n",
    "response_counts = pd.Series(all_responses).value_counts().reset_index()\n",
    "response_counts.columns = ['Tools', 'Count']\n",
    "\n",
    "# Chart using Altair with orange color\n",
    "chart = alt.Chart(response_counts).mark_bar(color='#F7931E').encode(\n",
    "    x='Count:Q',\n",
    "    y=alt.Y('Tools:N', sort='-x'),\n",
    "    tooltip=['Tools', 'Count']\n",
    ").properties(\n",
    "    title='Tools used for model registry and experiment tracking',\n",
    "    width=500,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tools used for model registry and experiment tracking](images/chart8.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools used for scheduling\n",
    "\n",
    "For scheduling, the majority of respondants have chosen Airflow. Also, there are other tools that were not listed in the survey that are popular among the users. Coiled is the least popular of the listed options.\n",
    "\n",
    "```{tip} Show code\n",
    ":class: dropdown \n",
    "\n",
    "```python\n",
    "# Mapping dictionary\n",
    "mapping_dict = {\n",
    "    # Airflow responses\n",
    "    \"Airflow\": \"Airflow\",\n",
    "    \"Airflow اير فلو\": \"Airflow\",\n",
    "    # Argo responses\n",
    "    \"Argo\": \"Argo\",\n",
    "    \"Argo  ارجو\": \"Argo\",\n",
    "    # Coiled responses\n",
    "    \"Coiled\": \"Coiled\",\n",
    "    \"Coiled  كويلد\": \"Coiled\",\n",
    "    # Dagster responses\n",
    "    \"Dagster\": \"Dagster\",\n",
    "    \"Dagster  داجستر\": \"Dagster\",\n",
    "    # Kubeflow responses\n",
    "    \"Kubeflow\": \"Kubeflow\",\n",
    "    \"Kubeflow  كيوب فلو\": \"Kubeflow\",\n",
    "    # Metaflow (outerbounds) responses\n",
    "    \"Metaflow (outerbounds)\": \"Metaflow (outerbounds)\",\n",
    "    \"Metaflow (outerbounds)(اوت باندز)  ميتا فلو\": \"Metaflow (outerbounds)\",\n",
    "    # Custom tool responses\n",
    "    \"Custom tool\": \"Custom tool\",\n",
    "    \"Ferramenta personalizada\": \"Custom tool\",\n",
    "    \"Herramientas personalizadas\": \"Custom tool\",\n",
    "    \"自定义工具\": \"Custom tool\",\n",
    "    \"Outil personnalisé\": \"Custom tool\",\n",
    "    \"أداة مخصصة\": \"Custom tool\",\n",
    "    # Other responses\n",
    "    \"Other\": \"Other\",\n",
    "    \"Outro\": \"Other\",\n",
    "    \"Otro\": \"Other\",\n",
    "    \"其它\": \"Other\",\n",
    "    \"Autre\": \"Other\",\n",
    "    \"أخرى\": \"Other\"\n",
    "}\n",
    "\n",
    "# Function to normalize responses\n",
    "def normalize_responses(response):\n",
    "    if isinstance(response, str):\n",
    "        response_split = [r.strip() for r in response.split(',')]\n",
    "        normalized = [mapping_dict.get(r, None) for r in response_split]\n",
    "        return [r for r in normalized if r is not None]\n",
    "    return []\n",
    "\n",
    "# Apply normalization and count responses\n",
    "df['Normalized_Responses'] = df['For scheduling, do you use any of the following tools? Select all that apply.'].apply(normalize_responses)\n",
    "all_responses = [item for sublist in df['Normalized_Responses'].dropna() for item in sublist]\n",
    "response_counts = pd.Series(all_responses).value_counts().reset_index()\n",
    "response_counts.columns = ['Tools', 'Count']\n",
    "\n",
    "# Chart using Altair with orange color\n",
    "chart = alt.Chart(response_counts).mark_bar(color='#F7931E').encode(\n",
    "    x='Count:Q',\n",
    "    y=alt.Y('Tools:N', sort='-x'),\n",
    "    tooltip=['Tools', 'Count']\n",
    ").properties(\n",
    "    title='Tools used for scheduling',\n",
    "    width=500,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tools used for scheduling](images/chart9.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time that a typical model training takes in ML projects\n",
    "\n",
    "Respondents usually take from some minutes to a day for a typical model training. It is not very common that they take less than a minute or more than a day.\n",
    "\n",
    "```{tip} Show code\n",
    ":class: dropdown \n",
    "\n",
    "```python\n",
    "# Mapping dictionary\n",
    "mapping_dict = {\n",
    "    # less than 10 seconds responses\n",
    "    \"less than 10 seconds\": \"less than 10 seconds\",\n",
    "    \"menos de 10 segundos\": \"less than 10 seconds\",\n",
    "    \"少于10秒\": \"less than 10 seconds\",\n",
    "    \"moins de 10 secondes\": \"less than 10 seconds\",\n",
    "    \"أقل من ١٠ ثوانٍ\": \"less than 10 seconds\",\n",
    "    # less than a minute responses\n",
    "    \"less than a minute\": \"less than a minute\",\n",
    "    \"menos de um minuto\": \"less than a minute\",\n",
    "    \"menos de un minuto\": \"less than a minute\",\n",
    "    \"少于1分钟\": \"less than a minute\",\n",
    "    \"moins d'une minute\": \"less than a minute\",\n",
    "    \"أقل من دقيقة\": \"less than a minute\",\n",
    "    # less than 10 minutes responses\n",
    "    \"less than 10 minutes\": \"less than 10 minutes\",\n",
    "    \"menos de 10 minutos\": \"less than 10 minutes\",\n",
    "    \"少于10分钟\": \"less than 10 minutes\",\n",
    "    \"moins de 10 minutes\": \"less than 10 minutes\",\n",
    "    \"أقل من ١٠ دقائق\": \"less than 10 minutes\",\n",
    "    # less than an hour responses\n",
    "    \"less than an hour\": \"less than an hour\",\n",
    "    \"menos de uma hora\": \"less than an hour\",\n",
    "    \"menos de una hora\": \"less than an hour\",\n",
    "    \"少于1小时\": \"less than an hour\",\n",
    "    \"moins d'une heure\": \"less than an hour\",\n",
    "    \"أقل من ساعة\": \"less than an hour\",\n",
    "    # less than a day responses\n",
    "    \"less than a day\": \"less than a day\",\n",
    "    \"menos de um dia\": \"less than a day\",\n",
    "    \"menos de un día\": \"less than a day\",\n",
    "    \"少于1天\": \"less than a day\",\n",
    "    \"moins d'une journée\": \"less than a day\",\n",
    "    \"أقل من يوم\": \"less than a day\",\n",
    "    # more than a day responses\n",
    "    \"more than a day\": \"more than a day\",\n",
    "    \"mais de um dia\": \"more than a day\",\n",
    "    \"más de un día\": \"more than a day\",\n",
    "    \"多于1天\": \"more than a day\",\n",
    "    \"plus d'une journée\": \"more than a day\",\n",
    "    \"أكثر من يوم\": \"more than a day\"\n",
    "}\n",
    "\n",
    "# Function to normalize responses\n",
    "def normalize_responses(response):\n",
    "    if isinstance(response, str):\n",
    "        response_split = [r.strip() for r in response.split(',')]\n",
    "        normalized = [mapping_dict.get(r, None) for r in response_split]\n",
    "        return [r for r in normalized if r is not None]\n",
    "    return []\n",
    "\n",
    "# Apply normalization and count responses\n",
    "df['Normalized_Responses'] = df['How long does a typical model training take in your ML projects?'].apply(normalize_responses)\n",
    "all_responses = [item for sublist in df['Normalized_Responses'].dropna() for item in sublist]\n",
    "response_counts = pd.Series(all_responses).value_counts().reset_index()\n",
    "response_counts.columns = ['Time', 'Count']\n",
    "\n",
    "# Chart using Altair with orange color\n",
    "chart = alt.Chart(response_counts).mark_bar(color='#F7931E').encode(\n",
    "    x='Count:Q',\n",
    "    y=alt.Y('Time:N', sort='-x'),\n",
    "    tooltip=['Time', 'Count']\n",
    ").properties(\n",
    "    title='Time taken for a typical model training',\n",
    "    width=500,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Time that a typical model training takes in ML projects](images/chart10.png)\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
